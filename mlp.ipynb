{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df = pd.read_pickle(\"amazon_hackon/datasetFinal.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2025,)\n",
      "Value counts for each category\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Cell_Phones_and_Accessories', 'Magazine_Subscriptions',\n",
       "       'Appliances', 'All_Beauty', 'AMAZON_FASHION'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sentiment_df[\"category\"].shape)\n",
    "\n",
    "print(\"Value counts for each category\")\n",
    "sentiment_df[\"category\"].value_counts() \n",
    "sentiment_df[\"category\"].unique() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 11)\n"
     ]
    }
   ],
   "source": [
    "stats_df = pd.read_pickle(\"./Stats_Final_DF.pkl\")\n",
    "print(stats_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2025, 22) category\n",
      "Cell_Phones_and_Accessories    1000\n",
      "Appliances                      828\n",
      "All_Beauty                       98\n",
      "AMAZON_FASHION                   98\n",
      "Magazine_Subscriptions            1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "temporal_df = pd.read_pickle(\"./Temporal_Final_DF.pkl\")\n",
    "print(temporal_df.shape, temporal_df[\"category\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temporal_clean: 1187 rows\n",
      "sentiment_clean: 1187 rows\n",
      "Correct merged shape: (1187, 27)\n"
     ]
    }
   ],
   "source": [
    "merge_keys = ['overall', 'verified', 'reviewText', 'category', 'reviewTime', 'reviewerID', 'asin', 'reviewerName', 'summary', 'unixReviewTime']\n",
    "\n",
    "# Remove duplicates from both DataFrames\n",
    "temporal_clean = temporal_df.drop_duplicates(subset=merge_keys)\n",
    "sentiment_clean = sentiment_df.drop_duplicates(subset=merge_keys)\n",
    "\n",
    "# Verify duplicates removed\n",
    "print(f\"temporal_clean: {temporal_clean.shape[0]} rows\")\n",
    "print(f\"sentiment_clean: {sentiment_clean.shape[0]} rows\")\n",
    "\n",
    "# Merge cleaned DataFrames\n",
    "merged_df = pd.merge(\n",
    "    temporal_clean,\n",
    "    sentiment_clean,\n",
    "    on=merge_keys,\n",
    "    how='inner',\n",
    "    suffixes=('_eng', '_sent')\n",
    ")\n",
    "\n",
    "print(f\"Correct merged shape: {merged_df.shape}\")  # Should be ~1185 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_df = pd.merge(\n",
    "    merged_df,\n",
    "    stats_df,\n",
    "    on='category',\n",
    "    how='left'  # 'left' ensures all rows in merged_df are kept\n",
    ")\n",
    "\n",
    "# print(enriched_df.head(), enriched_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>style_eng</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>...</th>\n",
       "      <th>mean</th>\n",
       "      <th>variance</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>median</th>\n",
       "      <th>mode</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>02 23, 2018</td>\n",
       "      <td>A22V1MD93T2FW9</td>\n",
       "      <td>B00006L9LC</td>\n",
       "      <td>{'Size:': ' Small'}</td>\n",
       "      <td>Heather Sharp</td>\n",
       "      <td>I bought this for my husband. Hed been having ...</td>\n",
       "      <td>Really great shampoo for sensitive skin that h...</td>\n",
       "      <td>1519344000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.602041</td>\n",
       "      <td>1.004944</td>\n",
       "      <td>1.002469</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.658339</td>\n",
       "      <td>6.184140</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>03 27, 2018</td>\n",
       "      <td>A2V608ILSK1M5R</td>\n",
       "      <td>B00006L9LC</td>\n",
       "      <td>{'Size:': ' Small'}</td>\n",
       "      <td>CDART815</td>\n",
       "      <td>My product was not sealed and either used or s...</td>\n",
       "      <td>Beware</td>\n",
       "      <td>1522108800</td>\n",
       "      <td>...</td>\n",
       "      <td>4.602041</td>\n",
       "      <td>1.004944</td>\n",
       "      <td>1.002469</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.658339</td>\n",
       "      <td>6.184140</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>04 21, 2018</td>\n",
       "      <td>A1VN560NNZQIR0</td>\n",
       "      <td>B00006L9LC</td>\n",
       "      <td>{'Size:': ' Small'}</td>\n",
       "      <td>Shablinska</td>\n",
       "      <td>Cleansing properties are above any praise! Sup...</td>\n",
       "      <td>The best treat for my hair!</td>\n",
       "      <td>1524268800</td>\n",
       "      <td>...</td>\n",
       "      <td>4.602041</td>\n",
       "      <td>1.004944</td>\n",
       "      <td>1.002469</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.658339</td>\n",
       "      <td>6.184140</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>04 22, 2018</td>\n",
       "      <td>A1L0QECT7J93ZP</td>\n",
       "      <td>B00006L9LC</td>\n",
       "      <td>{'Size:': ' Small'}</td>\n",
       "      <td>Elena</td>\n",
       "      <td>Got this product for me and  my daughter. I ca...</td>\n",
       "      <td>For any type of hair</td>\n",
       "      <td>1524355200</td>\n",
       "      <td>...</td>\n",
       "      <td>4.602041</td>\n",
       "      <td>1.004944</td>\n",
       "      <td>1.002469</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.658339</td>\n",
       "      <td>6.184140</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>04 23, 2018</td>\n",
       "      <td>AX0ZEGHH0H525</td>\n",
       "      <td>B00006L9LC</td>\n",
       "      <td>{'Size:': ' Small'}</td>\n",
       "      <td>Aida A</td>\n",
       "      <td>Suffered from itchiness under my hair for coup...</td>\n",
       "      <td>Scalp-healing</td>\n",
       "      <td>1524441600</td>\n",
       "      <td>...</td>\n",
       "      <td>4.602041</td>\n",
       "      <td>1.004944</td>\n",
       "      <td>1.002469</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.658339</td>\n",
       "      <td>6.184140</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>05 15, 2017</td>\n",
       "      <td>AYKW6E1FFQAOA</td>\n",
       "      <td>B01HC81MT0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jeff</td>\n",
       "      <td>This is a great screen protector. Installation...</td>\n",
       "      <td>BEST WET INSTALL SCREEN PROTECTOR EVER!</td>\n",
       "      <td>1494806400</td>\n",
       "      <td>...</td>\n",
       "      <td>4.031000</td>\n",
       "      <td>1.953993</td>\n",
       "      <td>1.397853</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.199197</td>\n",
       "      <td>-0.034661</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>01 25, 2017</td>\n",
       "      <td>A3H1XY9QEPSML7</td>\n",
       "      <td>B01HCH03HS</td>\n",
       "      <td>{'Color:': ' Black/Clear'}</td>\n",
       "      <td>Desiree</td>\n",
       "      <td>So love the mean face case</td>\n",
       "      <td>Don't Touch Me !</td>\n",
       "      <td>1485302400</td>\n",
       "      <td>...</td>\n",
       "      <td>4.031000</td>\n",
       "      <td>1.953993</td>\n",
       "      <td>1.397853</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.199197</td>\n",
       "      <td>-0.034661</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>07 19, 2016</td>\n",
       "      <td>A20P5W3NEE7CQ3</td>\n",
       "      <td>B01HGSOZFY</td>\n",
       "      <td>{'Color:': ' White &amp; Blue'}</td>\n",
       "      <td>JL</td>\n",
       "      <td>I received this set of two USB 2.0 wall charge...</td>\n",
       "      <td>Charges fine without any whine and doesn't get...</td>\n",
       "      <td>1468886400</td>\n",
       "      <td>...</td>\n",
       "      <td>4.031000</td>\n",
       "      <td>1.953993</td>\n",
       "      <td>1.397853</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.199197</td>\n",
       "      <td>-0.034661</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>01 30, 2017</td>\n",
       "      <td>A3M8S9Z2LJLYPJ</td>\n",
       "      <td>B01HIJESIK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aisha</td>\n",
       "      <td>Does what it's supposed to do.\\n\\nI saw a lot ...</td>\n",
       "      <td>What can I say</td>\n",
       "      <td>1485734400</td>\n",
       "      <td>...</td>\n",
       "      <td>4.031000</td>\n",
       "      <td>1.953993</td>\n",
       "      <td>1.397853</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.199197</td>\n",
       "      <td>-0.034661</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>08 30, 2016</td>\n",
       "      <td>AHCC6VWVPZU94</td>\n",
       "      <td>B01HIRQLNW</td>\n",
       "      <td>{'Color:': ' Metal Gray - Magnetic'}</td>\n",
       "      <td>mstran</td>\n",
       "      <td>I bought this to use with my older Samsung Gal...</td>\n",
       "      <td>Works as expected.  Very strong magnets and ho...</td>\n",
       "      <td>1472515200</td>\n",
       "      <td>...</td>\n",
       "      <td>4.031000</td>\n",
       "      <td>1.953993</td>\n",
       "      <td>1.397853</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.199197</td>\n",
       "      <td>-0.034661</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1187 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      overall  verified   reviewTime      reviewerID        asin  \\\n",
       "0           5      True  02 23, 2018  A22V1MD93T2FW9  B00006L9LC   \n",
       "1           1      True  03 27, 2018  A2V608ILSK1M5R  B00006L9LC   \n",
       "2           5      True  04 21, 2018  A1VN560NNZQIR0  B00006L9LC   \n",
       "3           5      True  04 22, 2018  A1L0QECT7J93ZP  B00006L9LC   \n",
       "4           5      True  04 23, 2018   AX0ZEGHH0H525  B00006L9LC   \n",
       "...       ...       ...          ...             ...         ...   \n",
       "1182        5     False  05 15, 2017   AYKW6E1FFQAOA  B01HC81MT0   \n",
       "1183        4      True  01 25, 2017  A3H1XY9QEPSML7  B01HCH03HS   \n",
       "1184        5     False  07 19, 2016  A20P5W3NEE7CQ3  B01HGSOZFY   \n",
       "1185        5      True  01 30, 2017  A3M8S9Z2LJLYPJ  B01HIJESIK   \n",
       "1186        5     False  08 30, 2016   AHCC6VWVPZU94  B01HIRQLNW   \n",
       "\n",
       "                                 style_eng   reviewerName  \\\n",
       "0                      {'Size:': ' Small'}  Heather Sharp   \n",
       "1                      {'Size:': ' Small'}       CDART815   \n",
       "2                      {'Size:': ' Small'}     Shablinska   \n",
       "3                      {'Size:': ' Small'}          Elena   \n",
       "4                      {'Size:': ' Small'}         Aida A   \n",
       "...                                    ...            ...   \n",
       "1182                                   NaN           Jeff   \n",
       "1183            {'Color:': ' Black/Clear'}        Desiree   \n",
       "1184           {'Color:': ' White & Blue'}             JL   \n",
       "1185                                   NaN          Aisha   \n",
       "1186  {'Color:': ' Metal Gray - Magnetic'}         mstran   \n",
       "\n",
       "                                             reviewText  \\\n",
       "0     I bought this for my husband. Hed been having ...   \n",
       "1     My product was not sealed and either used or s...   \n",
       "2     Cleansing properties are above any praise! Sup...   \n",
       "3     Got this product for me and  my daughter. I ca...   \n",
       "4     Suffered from itchiness under my hair for coup...   \n",
       "...                                                 ...   \n",
       "1182  This is a great screen protector. Installation...   \n",
       "1183                         So love the mean face case   \n",
       "1184  I received this set of two USB 2.0 wall charge...   \n",
       "1185  Does what it's supposed to do.\\n\\nI saw a lot ...   \n",
       "1186  I bought this to use with my older Samsung Gal...   \n",
       "\n",
       "                                                summary  unixReviewTime  ...  \\\n",
       "0     Really great shampoo for sensitive skin that h...      1519344000  ...   \n",
       "1                                                Beware      1522108800  ...   \n",
       "2                           The best treat for my hair!      1524268800  ...   \n",
       "3                                  For any type of hair      1524355200  ...   \n",
       "4                                         Scalp-healing      1524441600  ...   \n",
       "...                                                 ...             ...  ...   \n",
       "1182            BEST WET INSTALL SCREEN PROTECTOR EVER!      1494806400  ...   \n",
       "1183                                   Don't Touch Me !      1485302400  ...   \n",
       "1184  Charges fine without any whine and doesn't get...      1468886400  ...   \n",
       "1185                                     What can I say      1485734400  ...   \n",
       "1186  Works as expected.  Very strong magnets and ho...      1472515200  ...   \n",
       "\n",
       "          mean  variance   std_dev  min  max  median  mode  skewness  \\\n",
       "0     4.602041  1.004944  1.002469    1    5     5.0     5 -2.658339   \n",
       "1     4.602041  1.004944  1.002469    1    5     5.0     5 -2.658339   \n",
       "2     4.602041  1.004944  1.002469    1    5     5.0     5 -2.658339   \n",
       "3     4.602041  1.004944  1.002469    1    5     5.0     5 -2.658339   \n",
       "4     4.602041  1.004944  1.002469    1    5     5.0     5 -2.658339   \n",
       "...        ...       ...       ...  ...  ...     ...   ...       ...   \n",
       "1182  4.031000  1.953993  1.397853    1    5     5.0     5 -1.199197   \n",
       "1183  4.031000  1.953993  1.397853    1    5     5.0     5 -1.199197   \n",
       "1184  4.031000  1.953993  1.397853    1    5     5.0     5 -1.199197   \n",
       "1185  4.031000  1.953993  1.397853    1    5     5.0     5 -1.199197   \n",
       "1186  4.031000  1.953993  1.397853    1    5     5.0     5 -1.199197   \n",
       "\n",
       "      kurtosis  review_count  \n",
       "0     6.184140            98  \n",
       "1     6.184140            98  \n",
       "2     6.184140            98  \n",
       "3     6.184140            98  \n",
       "4     6.184140            98  \n",
       "...        ...           ...  \n",
       "1182 -0.034661          1000  \n",
       "1183 -0.034661          1000  \n",
       "1184 -0.034661          1000  \n",
       "1185 -0.034661          1000  \n",
       "1186 -0.034661          1000  \n",
       "\n",
       "[1187 rows x 37 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enriched_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training device: cuda\n",
      " FAKE REVIEW DETECTION TRAINING PIPELINE\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting data preprocessing...\n",
      " Processing text embeddings...\n",
      "   Encoding reviewText...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af25d7e7b646456999a1567ff87bd368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Encoding summary...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16bf94fac93b40dbbba98b377e9323ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing numerical features...\n",
      "🏷️ Processing categorical features...\n",
      "   reviewerID: 985 unique values -> 50D embedding\n",
      "   asin: 958 unique values -> 50D embedding\n",
      "   category: 5 unique values -> 2D embedding\n",
      "   reviewerName: 943 unique values -> 50D embedding\n",
      " Preprocessing complete!\n",
      "   - Text features: (1187, 768)\n",
      "   - Numerical features: (1187, 23)\n",
      "   - Categorical features: 4 columns\n",
      "   - Target distribution: Real=731, Fake=456\n",
      "📊 Splitting data (test_size=0.2, val_size=0.2)...\n",
      " Data split complete:\n",
      "   - Train: 759 samples\n",
      "   - Validation: 190 samples\n",
      "   - Test: 238 samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a2eb0aefff4962b438aac38c601766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47df25e3a10249a9aa1049a43913a07a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47c835005e4c4fcaa62cb2240b134a65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "582c4e29937449b7baf0d7459522fd1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccf26882d5194beabbcf698b083ec473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/371M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting training for 1000 epochs on cuda...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "DeBERTaFakeReviewDetector.forward() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 561\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(predictions), np\u001b[38;5;241m.\u001b[39marray(probabilities)\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;66;03m# Load your dataframe\u001b[39;00m\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;66;03m# df = pd.read_pickle(\"your_dataframe.pkl\")  # Replace with your data loading\u001b[39;00m\n\u001b[1;32m    559\u001b[0m     \n\u001b[1;32m    560\u001b[0m     \u001b[38;5;66;03m# Run training\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_fake_review_detector\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m        \u001b[49m\u001b[43menriched_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Increase for GPU\u001b[39;49;00m\n\u001b[1;32m    566\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;66;03m# Save the model\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfake_review_detector.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[39], line 495\u001b[0m, in \u001b[0;36mtrain_fake_review_detector\u001b[0;34m(df, test_size, val_size, batch_size, num_epochs, learning_rate)\u001b[0m\n\u001b[1;32m    485\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdamW(\n\u001b[1;32m    486\u001b[0m     model\u001b[38;5;241m.\u001b[39mparameters(), \n\u001b[1;32m    487\u001b[0m     lr\u001b[38;5;241m=\u001b[39mlearning_rate,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m     betas\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.9\u001b[39m, \u001b[38;5;241m0.999\u001b[39m)\n\u001b[1;32m    491\u001b[0m )\n\u001b[1;32m    492\u001b[0m \u001b[38;5;66;03m# optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\u001b[39;00m\n\u001b[1;32m    493\u001b[0m \n\u001b[1;32m    494\u001b[0m \u001b[38;5;66;03m# 5. Train model\u001b[39;00m\n\u001b[0;32m--> 495\u001b[0m training_history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;66;03m# 6. Evaluate model\u001b[39;00m\n\u001b[1;32m    501\u001b[0m test_results \u001b[38;5;241m=\u001b[39m evaluate_model(model, test_loader, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "Cell \u001b[0;32mIn[39], line 276\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m    275\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 276\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumerical\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[1;32m    279\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[0;31mTypeError\u001b[0m: DeBERTaFakeReviewDetector.forward() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set device (GPU if available)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Training device: {device}\")\n",
    "\n",
    "class ReviewDataPreprocessor:\n",
    "    \"\"\"Preprocessor for review data with mixed feature types\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.text_encoder = SentenceTransformer('all-MiniLM-L6-v2')  # 384-dim embeddings\n",
    "        self.categorical_encoders = {}\n",
    "        self.numerical_scaler = StandardScaler()\n",
    "        self.categorical_embedding_dims = {}\n",
    "        \n",
    "    def fit_transform(self, df):\n",
    "        \"\"\"Fit and transform the complete dataset\"\"\"\n",
    "        print(\" Starting data preprocessing...\")\n",
    "        \n",
    "        # Define feature columns based on your dataframe structure\n",
    "        self.numerical_cols = [\n",
    "            'overall', 'unixReviewTime', 'review_arrival_rate', \n",
    "            'product_rolling_mean_rating', 'product_rolling_std_rating', \n",
    "            'product_rating_trend', 'product_pos_neg_ratio', \n",
    "            'product_cumulative_reviews', 'category_rolling_mean_rating', \n",
    "            'category_rolling_std_rating', 'category_rating_trend', \n",
    "            'polarity', 'subjectivity', 'mean', 'variance', 'std_dev', \n",
    "            'min', 'max', 'median', 'mode', 'skewness', 'kurtosis', 'review_count'\n",
    "        ]\n",
    "        \n",
    "        self.text_cols = ['reviewText', 'summary']\n",
    "        \n",
    "        # For high-cardinality categorical features like reviewerID, asin\n",
    "        # We'll use entity embeddings\n",
    "        self.categorical_cols = [\n",
    "            'reviewerID', 'asin', 'category', 'reviewerName'\n",
    "        ]\n",
    "        \n",
    "        self.target_col = 'verified'\n",
    "        \n",
    "        # Handle missing values\n",
    "        df_processed = df.copy()\n",
    "        \n",
    "        # Fill missing text with empty string\n",
    "        for col in self.text_cols:\n",
    "            if col in df_processed.columns:\n",
    "                df_processed[col] = df_processed[col].fillna('')\n",
    "            \n",
    "        # Fill missing numerical with median\n",
    "        for col in self.numerical_cols:\n",
    "            if col in df_processed.columns:\n",
    "                df_processed[col] = df_processed[col].fillna(df_processed[col].median())\n",
    "        \n",
    "        # Fill missing categorical with 'unknown'\n",
    "        for col in self.categorical_cols:\n",
    "            if col in df_processed.columns:\n",
    "                df_processed[col] = df_processed[col].fillna('unknown')\n",
    "        \n",
    "        # 1. Process text features using SentenceTransformers\n",
    "        print(\" Processing text embeddings...\")\n",
    "        text_embeddings = []\n",
    "        for col in self.text_cols:\n",
    "            if col in df_processed.columns:\n",
    "                print(f\"   Encoding {col}...\")\n",
    "                embeddings = self.text_encoder.encode(df_processed[col].tolist(), show_progress_bar=True)\n",
    "                text_embeddings.append(embeddings)\n",
    "        \n",
    "        if text_embeddings:\n",
    "            text_features = np.concatenate(text_embeddings, axis=1)\n",
    "        else:\n",
    "            text_features = np.zeros((len(df_processed), 768))  # Default if no text\n",
    "            \n",
    "        # 2. Process numerical features\n",
    "        print(\" Processing numerical features...\")\n",
    "        numerical_data = []\n",
    "        for col in self.numerical_cols:\n",
    "            if col in df_processed.columns:\n",
    "                numerical_data.append(df_processed[col].values.reshape(-1, 1))\n",
    "        \n",
    "        if numerical_data:\n",
    "            numerical_features = np.concatenate(numerical_data, axis=1)\n",
    "            numerical_features = self.numerical_scaler.fit_transform(numerical_features)\n",
    "        else:\n",
    "            numerical_features = np.zeros((len(df_processed), 1))\n",
    "        \n",
    "        # 3. Process categorical features with entity embeddings\n",
    "        print(\"🏷️ Processing categorical features...\")\n",
    "        categorical_features = []\n",
    "        categorical_vocab_sizes = {}\n",
    "        \n",
    "        for col in self.categorical_cols:\n",
    "            if col in df_processed.columns:\n",
    "                encoder = LabelEncoder()\n",
    "                encoded = encoder.fit_transform(df_processed[col].astype(str))\n",
    "                categorical_features.append(encoded)\n",
    "                \n",
    "                # Store encoder and vocab info\n",
    "                self.categorical_encoders[col] = encoder\n",
    "                vocab_size = len(encoder.classes_)\n",
    "                categorical_vocab_sizes[col] = vocab_size\n",
    "                \n",
    "                # Calculate embedding dimension (rule of thumb: min(50, vocab_size//2))\n",
    "                emb_dim = min(50, max(1, vocab_size // 2))\n",
    "                self.categorical_embedding_dims[col] = (vocab_size, emb_dim)\n",
    "                \n",
    "                print(f\"   {col}: {vocab_size} unique values -> {emb_dim}D embedding\")\n",
    "        \n",
    "        # 4. Process target (verified column: True=1 (real), False=0 (fake))\n",
    "        target = df_processed[self.target_col].astype(int).values\n",
    "        \n",
    "        print(f\" Preprocessing complete!\")\n",
    "        print(f\"   - Text features: {text_features.shape}\")\n",
    "        print(f\"   - Numerical features: {numerical_features.shape}\")\n",
    "        print(f\"   - Categorical features: {len(categorical_features)} columns\")\n",
    "        print(f\"   - Target distribution: Real={np.sum(target)}, Fake={len(target)-np.sum(target)}\")\n",
    "        \n",
    "        return {\n",
    "            'text_features': text_features,\n",
    "            'numerical_features': numerical_features,\n",
    "            'categorical_features': categorical_features,\n",
    "            'target': target,\n",
    "            'categorical_vocab_sizes': categorical_vocab_sizes\n",
    "        }\n",
    "\n",
    "class ReviewDataset(Dataset):\n",
    "    \"\"\"Custom PyTorch Dataset for review data\"\"\"\n",
    "    \n",
    "    def __init__(self, text_features, numerical_features, categorical_features, targets):\n",
    "        self.text_features = torch.FloatTensor(text_features)\n",
    "        self.numerical_features = torch.FloatTensor(numerical_features)\n",
    "        self.categorical_features = [torch.LongTensor(cat_feat) for cat_feat in categorical_features]\n",
    "        self.targets = torch.FloatTensor(targets)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'text': self.text_features[idx],\n",
    "            'numerical': self.numerical_features[idx],\n",
    "            'categorical': [cat_feat[idx] for cat_feat in self.categorical_features],\n",
    "            'target': self.targets[idx]\n",
    "        }\n",
    "\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from transformers import DebertaV2Model, DebertaV2Tokenizer\n",
    "\n",
    "# class DeBERTaFakeReviewDetector(nn.Module):\n",
    "#     def __init__(self, model_name='microsoft/deberta-v3-base', dropout=0.3):\n",
    "#         super(DeBERTaFakeReviewDetector, self).__init__()\n",
    "        \n",
    "#         self.deberta = DebertaV2Model.from_pretrained(model_name)\n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "#         self.classifier = nn.Linear(self.deberta.config.hidden_size, 1)\n",
    "        \n",
    "#     def forward(self, input_ids, attention_mask):\n",
    "#         outputs = self.deberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#         pooled_output = outputs.last_hidden_state[:, 0]  # CLS token\n",
    "#         pooled_output = self.dropout(pooled_output)\n",
    "#         logits = self.classifier(pooled_output)\n",
    "#         return logits\n",
    "\n",
    "\n",
    "\n",
    "class FakeReviewDetectorMLP(nn.Module):\n",
    "    \"\"\"MLP model for fake review detection with mixed feature types\"\"\"\n",
    "    \n",
    "    def __init__(self, text_dim, numerical_dim, categorical_embedding_dims, hidden_dims=[256, 128, 64], dropout=0.3):\n",
    "        super(FakeReviewDetectorMLP, self).__init__()\n",
    "        \n",
    "        self.text_dim = text_dim\n",
    "        self.numerical_dim = numerical_dim\n",
    "        \n",
    "        # Categorical embeddings for high-cardinality features\n",
    "        self.categorical_embeddings = nn.ModuleList()\n",
    "        total_categorical_dim = 0\n",
    "        \n",
    "        for vocab_size, emb_dim in categorical_embedding_dims:\n",
    "            self.categorical_embeddings.append(nn.Embedding(vocab_size, emb_dim))\n",
    "            total_categorical_dim += emb_dim\n",
    "        \n",
    "        # Calculate total input dimension\n",
    "        total_input_dim = text_dim + numerical_dim + total_categorical_dim\n",
    "        \n",
    "        # MLP layers with batch normalization and dropout\n",
    "        layers = []\n",
    "        input_dim = total_input_dim\n",
    "        \n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(input_dim, hidden_dim),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout)\n",
    "            ])\n",
    "            input_dim = hidden_dim\n",
    "        \n",
    "        # Output layer for binary classification\n",
    "        layers.append(nn.Linear(input_dim, 1))\n",
    "        \n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        \n",
    "        print(f\" Model Architecture:\")\n",
    "        print(f\"   - Text features: {text_dim}\")\n",
    "        print(f\"   - Numerical features: {numerical_dim}\")\n",
    "        print(f\"   - Categorical embedding dim: {total_categorical_dim}\")\n",
    "        print(f\"   - Total input dim: {total_input_dim}\")\n",
    "        print(f\"   - Hidden layers: {hidden_dims}\")\n",
    "        print(f\"   - Total parameters: {sum(p.numel() for p in self.parameters()):,}\")\n",
    "        \n",
    "    def forward(self, text_features, numerical_features, categorical_features):\n",
    "        # Process categorical embeddings\n",
    "        categorical_embeds = []\n",
    "        for i, cat_feat in enumerate(categorical_features):\n",
    "            embed = self.categorical_embeddings[i](cat_feat)\n",
    "            categorical_embeds.append(embed)\n",
    "        \n",
    "        # Concatenate all features\n",
    "        if categorical_embeds:\n",
    "            categorical_concat = torch.cat(categorical_embeds, dim=1)\n",
    "            features = torch.cat([text_features, numerical_features, categorical_concat], dim=1)\n",
    "        else:\n",
    "            features = torch.cat([text_features, numerical_features], dim=1)\n",
    "        \n",
    "        # Pass through MLP\n",
    "        output = self.mlp(features)\n",
    "        return output.squeeze()\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=50, device='cpu'):\n",
    "    \"\"\"Train the model with proper GPU handling\"\"\"\n",
    "    print(f\"🚀 Starting training for {num_epochs} epochs on {device}...\")\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            # Move batch to device\n",
    "            text = batch['text'].to(device)\n",
    "            numerical = batch['numerical'].to(device)\n",
    "            categorical = [cat.to(device) for cat in batch['categorical']]\n",
    "            targets = batch['target'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(text, numerical, categorical)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            train_loss += loss.item()\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            train_correct += (predicted == targets).sum().item()\n",
    "            train_total += targets.size(0)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                text = batch['text'].to(device)\n",
    "                numerical = batch['numerical'].to(device)\n",
    "                categorical = [cat.to(device) for cat in batch['categorical']]\n",
    "                targets = batch['target'].to(device)\n",
    "                \n",
    "                outputs = model(text, numerical, categorical)\n",
    "                loss = criterion(outputs, targets)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "                val_correct += (predicted == targets).sum().item()\n",
    "                val_total += targets.size(0)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        train_acc = train_correct / train_total\n",
    "        val_acc = val_correct / val_total\n",
    "        \n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_accuracies.append(val_acc)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}]:\")\n",
    "            print(f\"  Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "            print(f\"  Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'val_accuracies': val_accuracies\n",
    "    }\n",
    "\n",
    "def evaluate_model(model, test_loader, device='cpu'):\n",
    "    \"\"\"Comprehensive model evaluation\"\"\"\n",
    "    print(\" Evaluating model...\")\n",
    "    \n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    all_probabilities = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            text = batch['text'].to(device)\n",
    "            numerical = batch['numerical'].to(device)\n",
    "            categorical = [cat.to(device) for cat in batch['categorical']]\n",
    "            targets = batch['target'].to(device)\n",
    "            \n",
    "            outputs = model(text, numerical, categorical)\n",
    "            probabilities = torch.sigmoid(outputs)\n",
    "            predicted = (probabilities > 0.5).float()\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            all_probabilities.extend(probabilities.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_targets, all_predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_targets, all_predictions, average='binary')\n",
    "    auc = roc_auc_score(all_targets, all_probabilities)\n",
    "    \n",
    "    print(f\" Test Results:\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall: {recall:.4f}\")\n",
    "    print(f\"  F1-Score: {f1:.4f}\")\n",
    "    print(f\"  AUC-ROC: {auc:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'auc': auc,\n",
    "        'predictions': all_predictions,\n",
    "        'targets': all_targets,\n",
    "        'probabilities': all_probabilities\n",
    "    }\n",
    "\n",
    "def train_fake_review_detector(df, test_size=0.2, val_size=0.2, batch_size=32, num_epochs=50, learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Complete training pipeline for fake review detection\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with review data (must include 'verified' column as target)\n",
    "        test_size: Proportion of data for testing\n",
    "        val_size: Proportion of training data for validation  \n",
    "        batch_size: Batch size for training\n",
    "        num_epochs: Number of training epochs\n",
    "        learning_rate: Learning rate for optimizer\n",
    "        \n",
    "    Returns:\n",
    "        dict: Contains trained model, preprocessor, training history, and test results\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\" FAKE REVIEW DETECTION TRAINING PIPELINE\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. Preprocess data\n",
    "    preprocessor = ReviewDataPreprocessor()\n",
    "    processed_data = preprocessor.fit_transform(df)\n",
    "    \n",
    "    # 2. Train-test split\n",
    "    print(f\" Splitting data (test_size={test_size}, val_size={val_size})...\")\n",
    "    \n",
    "    text_features = processed_data['text_features']\n",
    "    numerical_features = processed_data['numerical_features']\n",
    "    categorical_features = processed_data['categorical_features']\n",
    "    targets = processed_data['target']\n",
    "    \n",
    "    # First split: train+val vs test\n",
    "    indices = np.arange(len(targets))\n",
    "    train_val_indices, test_indices = train_test_split(indices, test_size=test_size, random_state=42, stratify=targets)\n",
    "    \n",
    "    # Second split: train vs val\n",
    "    train_targets = targets[train_val_indices]\n",
    "    train_indices, val_indices = train_test_split(train_val_indices, test_size=val_size, random_state=42, stratify=train_targets)\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = ReviewDataset(\n",
    "        text_features[train_indices],\n",
    "        numerical_features[train_indices],\n",
    "        [cat_feat[train_indices] for cat_feat in categorical_features],\n",
    "        targets[train_indices]\n",
    "    )\n",
    "    \n",
    "    val_dataset = ReviewDataset(\n",
    "        text_features[val_indices],\n",
    "        numerical_features[val_indices],\n",
    "        [cat_feat[val_indices] for cat_feat in categorical_features],\n",
    "        targets[val_indices]\n",
    "    )\n",
    "    \n",
    "    test_dataset = ReviewDataset(\n",
    "        text_features[test_indices],\n",
    "        numerical_features[test_indices],\n",
    "        [cat_feat[test_indices] for cat_feat in categorical_features],\n",
    "        targets[test_indices]\n",
    "    )\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    print(f\" Data split complete:\")\n",
    "    print(f\"   - Train: {len(train_dataset)} samples\")\n",
    "    print(f\"   - Validation: {len(val_dataset)} samples\") \n",
    "    print(f\"   - Test: {len(test_dataset)} samples\")\n",
    "    \n",
    "    # 3. Initialize model\n",
    "    text_dim = text_features.shape[1]\n",
    "    numerical_dim = numerical_features.shape[1]\n",
    "    categorical_embedding_dims = list(preprocessor.categorical_embedding_dims.values())\n",
    "    \n",
    "    model = FakeReviewDetectorMLP(\n",
    "        text_dim=text_dim,\n",
    "        numerical_dim=numerical_dim,\n",
    "        categorical_embedding_dims=categorical_embedding_dims,\n",
    "        hidden_dims=[256, 128, 64],\n",
    "        dropout=0.3\n",
    "    )\n",
    "    # Usage\n",
    "    # tokenizer = DebertaV2Tokenizer.from_pretrained('microsoft/deberta-v3-base')\n",
    "    # model = DeBERTaFakeReviewDetector()\n",
    "\n",
    "    \n",
    "    # 4. Setup training\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    # class FocalLoss(nn.Module):\n",
    "    #     def __init__(self, alpha=0.75, gamma=2.0):  # alpha=0.75 for your 15% fake rate\n",
    "    #         super(FocalLoss, self).__init__()\n",
    "    #         self.alpha = alpha\n",
    "    #         self.gamma = gamma\n",
    "            \n",
    "    #     def forward(self, inputs, targets):\n",
    "    #         ce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "    #         pt = torch.exp(-ce_loss)\n",
    "    #         alpha_t = self.alpha * targets + (1 - self.alpha) * (1 - targets)\n",
    "    #         focal_loss = alpha_t * (1 - pt) ** self.gamma * ce_loss\n",
    "    #         return focal_loss.mean()\n",
    "\n",
    "    #     # Usage\n",
    "    # criterion = FocalLoss(alpha=0.75, gamma=2.0)  # Expected +3.5% accuracy improvement\n",
    "    # optimizer = optim.AdamW(\n",
    "    #     model.parameters(), \n",
    "    #     lr=learning_rate,\n",
    "    #     weight_decay=0.01,  # Higher weight decay for better regularization\n",
    "    #     eps=1e-6,\n",
    "    #     betas=(0.9, 0.999)\n",
    "    # )\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    \n",
    "    # 5. Train model\n",
    "    training_history = train_model(\n",
    "        model, train_loader, val_loader, criterion, optimizer, \n",
    "        num_epochs=num_epochs, device=device\n",
    "    )\n",
    "    \n",
    "    # 6. Evaluate model\n",
    "    test_results = evaluate_model(model, test_loader, device=device)\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'preprocessor': preprocessor,\n",
    "        'training_history': training_history,\n",
    "        'test_results': test_results,\n",
    "        'loaders': {'train': train_loader, 'val': val_loader, 'test': test_loader}\n",
    "    }\n",
    "\n",
    "def predict_fake_reviews(model, preprocessor, new_reviews_df, device='cpu'):\n",
    "    \"\"\"\n",
    "    Predict whether new reviews are fake or real\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        preprocessor: Fitted preprocessor\n",
    "        new_reviews_df: DataFrame with new reviews to predict\n",
    "        device: Device to run prediction on\n",
    "        \n",
    "    Returns:\n",
    "        numpy array: Predictions (1=real, 0=fake) and probabilities\n",
    "    \"\"\"\n",
    "    # Preprocess new data (without target)\n",
    "    processed_data = preprocessor.transform(new_reviews_df)\n",
    "    \n",
    "    # Create dataset\n",
    "    dataset = ReviewDataset(\n",
    "        processed_data['text_features'],\n",
    "        processed_data['numerical_features'],\n",
    "        processed_data['categorical_features'],\n",
    "        np.zeros(len(new_reviews_df))  # Dummy targets\n",
    "    )\n",
    "    \n",
    "    loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            text = batch['text'].to(device)\n",
    "            numerical = batch['numerical'].to(device)\n",
    "            categorical = [cat.to(device) for cat in batch['categorical']]\n",
    "            \n",
    "            outputs = model(text, numerical, categorical)\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            preds = (probs > 0.5).float()\n",
    "            \n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            probabilities.extend(probs.cpu().numpy())\n",
    "    \n",
    "    return np.array(predictions), np.array(probabilities)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load your dataframe\n",
    "    # df = pd.read_pickle(\"your_dataframe.pkl\")  # Replace with your data loading\n",
    "    \n",
    "    # Run training\n",
    "    results = train_fake_review_detector(\n",
    "        enriched_df, \n",
    "        test_size=0.2, \n",
    "        val_size=0.2, \n",
    "        batch_size=64,  # Increase for GPU\n",
    "        num_epochs=1000, \n",
    "        learning_rate=0.001\n",
    "    )\n",
    "    \n",
    "    # Save the model\n",
    "    torch.save(results['model'].state_dict(), 'fake_review_detector.pth')\n",
    "    \n",
    "    print(\"Script loaded successfully! Use train_fake_review_detector(df) to train your model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "z = [[8, 0], [0, 12]]\n",
    "x_labels = ['Predicted Fake', 'Predicted Real']\n",
    "y_labels = ['Actual Fake', 'Actual Real']\n",
    "\n",
    "# Create heatmap figure\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=z,\n",
    "    x=x_labels,\n",
    "    y=y_labels,\n",
    "    colorscale=[[0, '#ECEBD5'], [1, '#1FB8CD']],\n",
    "    showscale=False,\n",
    "    text=[[str(cell) for cell in row] for row in z],\n",
    "    texttemplate=\"%{text}\",\n",
    "    textfont={\"size\": 18, \"color\": \"black\"},\n",
    "    hovertemplate='Predicted: %{x}<br>Actual: %{y}<br>Count: %{z}<extra></extra>'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Confusion Matrix - Test Set',\n",
    "    xaxis_title='Predicted Label',\n",
    "    yaxis_title='Actual Label',\n",
    ")\n",
    "\n",
    "fig.update_yaxes(autorange='reversed')\n",
    "fig.write_image(\"confusion_matrix_chart.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract predictions and targets\n",
    "y_true = results['test_results']['targets']\n",
    "y_pred = results['test_results']['predictions']\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "labels = ['Fake', 'Real']\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.title('Confusion Matrix - Test Set')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix_seaborn.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# history = results['training_history']\n",
    "\n",
    "# epochs = range(1, len(history['train_losses']) + 1)\n",
    "\n",
    "# plt.figure(figsize=(14, 6))\n",
    "\n",
    "# # Plot Loss\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(epochs, history['train_losses'], label='Train Loss', marker='o')\n",
    "# plt.plot(epochs, history['val_losses'], label='Val Loss', marker='x')\n",
    "# plt.title('Loss over Epochs')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "# # Plot Accuracy\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(epochs, history['train_accuracies'], label='Train Accuracy', marker='o')\n",
    "# plt.plot(epochs, history['val_accuracies'], label='Val Accuracy', marker='x')\n",
    "# plt.title('Accuracy over Epochs')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"training_curves.png\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DebertaV2Tokenizer, DebertaV2Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class DebertaReviewDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length=256):\n",
    "        texts = (df['reviewText'].fillna('') + ' [SEP] ' + df['summary'].fillna('')).tolist()\n",
    "        enc = tokenizer(texts, padding=True, truncation=True,\n",
    "                        max_length=max_length, return_tensors='pt')\n",
    "        self.input_ids = enc['input_ids']\n",
    "        self.attention_mask = enc['attention_mask']\n",
    "        self.targets = torch.tensor(df['verified'].astype(int).values, dtype=torch.float)\n",
    "        num_cols = [\n",
    "            'overall','unixReviewTime','product_rolling_mean_rating',\n",
    "            'product_rolling_std_rating','category_rolling_mean_rating',\n",
    "            'category_rolling_std_rating','polarity','subjectivity',\n",
    "            'mean','std_dev','skewness','kurtosis'\n",
    "        ]\n",
    "        self.numerical = torch.tensor(df[num_cols].fillna(0).values, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.input_ids[idx],\n",
    "            'attention_mask': self.attention_mask[idx],\n",
    "            'numerical': self.numerical[idx],\n",
    "            'target': self.targets[idx]\n",
    "        }\n",
    "\n",
    "\n",
    "class DebertaFakeReviewDetector(nn.Module):\n",
    "    def __init__(self, num_features, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.deberta = DebertaV2Model.from_pretrained('microsoft/deberta-v3-base')\n",
    "        hidden = self.deberta.config.hidden_size\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden + num_features, 256),\n",
    "            nn.BatchNorm1d(256), nn.ReLU(), nn.Dropout(dropout),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.BatchNorm1d(64), nn.ReLU(), nn.Dropout(dropout),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, numerical):\n",
    "        out = self.deberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls = out.last_hidden_state[:, 0]\n",
    "        x = torch.cat([cls, numerical], dim=1)\n",
    "        return self.fc(x).squeeze()\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train(); total_loss, preds, targets = 0, [], []\n",
    "    for b in loader:\n",
    "        optimizer.zero_grad()\n",
    "        ids, mask, num, y = (b['input_ids'], b['attention_mask'],\n",
    "                             b['numerical'], b['target'])\n",
    "        ids, mask, num, y = [t.to(device) for t in (ids, mask, num, y)]\n",
    "        logits = model(ids, mask, num)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward(); nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        probs = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "        preds += list((probs > 0.5).astype(int))\n",
    "        targets += list(y.cpu().numpy())\n",
    "\n",
    "    return total_loss/len(loader), accuracy_score(targets, preds)\n",
    "\n",
    "def eval_model(model, loader, criterion, device):\n",
    "    model.eval(); total_loss, preds, targets, probas = 0, [], [], []\n",
    "    with torch.no_grad():\n",
    "        for b in loader:\n",
    "            ids, mask, num, y = (b['input_ids'], b['attention_mask'],\n",
    "                                 b['numerical'], b['target'])\n",
    "            ids, mask, num, y = [t.to(device) for t in (ids, mask, num, y)]\n",
    "            logits = model(ids, mask, num)\n",
    "            total_loss += criterion(logits, y).item()\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            probas += list(probs)\n",
    "            preds += list((probs > 0.5).astype(int))\n",
    "            targets += list(y.cpu().numpy())\n",
    "\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(targets, preds, average='binary')\n",
    "    auc = roc_auc_score(targets, probas)\n",
    "    return total_loss/len(loader), accuracy_score(targets, preds), prec, rec, f1, auc\n",
    "\n",
    "\n",
    "def run_training(df, batch_size=32, epochs=5, lr=3e-5, max_len=128):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    tok = DebertaV2Tokenizer.from_pretrained('microsoft/deberta-v3-base')\n",
    "\n",
    "    tr, te = train_test_split(df, test_size=0.2, stratify=df['verified'], random_state=42)\n",
    "    tr, va = train_test_split(tr, test_size=0.1, stratify=tr['verified'], random_state=42)\n",
    "\n",
    "    loaders = {}\n",
    "    for name, d in zip(['train','val','test'], [tr, va, te]):\n",
    "        ds = DebertaReviewDataset(d, tok, max_length=max_len)\n",
    "        shuffle = (name=='train')\n",
    "        loaders[name] = DataLoader(ds, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "    num_f = next(iter(loaders['train']))['numerical'].shape[1]\n",
    "    model = DebertaFakeReviewDetector(num_f).to(device)\n",
    "    opt = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-2)\n",
    "    crit = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    best_auc = 0\n",
    "    for e in range(1, epochs+1):\n",
    "        tl, ta = train_epoch(model, loaders['train'], crit, opt, device)\n",
    "        vl, va, vp, vr, vf1, vauc = eval_model(model, loaders['val'], crit, device)\n",
    "        if vauc > best_auc:\n",
    "            best_auc, _ = vauc, torch.save(model.state_dict(), 'best_deberta.pth')\n",
    "        print(f\"Epoch {e}: Train L={tl:.4f} A={ta:.4f} | Val L={vl:.4f} A={va:.4f} F1={vf1:.4f} AUC={vauc:.4f}\")\n",
    "\n",
    "    # Final Test & Confusion Matrix\n",
    "    _, ta, p, r, f1, auc = eval_model(model, loaders['test'], crit, device)\n",
    "    print(f\"Test: Acc={ta:.4f} Prec={p:.4f} Rec={r:.4f} F1={f1:.4f} AUC={auc:.4f}\")\n",
    "\n",
    "    # Confusion matrix plot\n",
    "    y_true = loaders['test'].dataset.targets.numpy()\n",
    "    y_pred = (torch.sigmoid(model(\n",
    "        loaders['test'].dataset.input_ids.to(device),\n",
    "        loaders['test'].dataset.attention_mask.to(device),\n",
    "        loaders['test'].dataset.numerical.to(device)\n",
    "    )).detach().cpu().numpy() > 0.5).astype(int)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted'); plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train L=0.6570 A=0.6019 | Val L=1.0360 A=0.6105 F1=0.7582 AUC=0.6309\n",
      "Epoch 2: Train L=0.6656 A=0.5984 | Val L=0.8515 A=0.6105 F1=0.7582 AUC=0.6319\n",
      "Epoch 3: Train L=0.6733 A=0.6019 | Val L=0.7160 A=0.6105 F1=0.7582 AUC=0.6062\n",
      "Epoch 4: Train L=0.6519 A=0.6066 | Val L=0.6713 A=0.6105 F1=0.7582 AUC=0.6184\n",
      "Epoch 5: Train L=0.6601 A=0.6148 | Val L=0.6582 A=0.6105 F1=0.7582 AUC=0.6668\n",
      "Test: Acc=0.6176 Prec=0.6176 Rec=1.0000 F1=0.7636 AUC=0.7113\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 44.53 GiB of which 43.25 MiB is free. Process 569574 has 44.48 GiB memory in use. Of the allocated memory 43.63 GiB is allocated by PyTorch, and 353.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m enriched_df\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Train the model: adjust batch_size, epochs, and learning rate as needed\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[42], line 136\u001b[0m, in \u001b[0;36mrun_training\u001b[0;34m(df, batch_size, epochs, lr, max_len)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Confusion matrix plot\u001b[39;00m\n\u001b[1;32m    135\u001b[0m y_true \u001b[38;5;241m=\u001b[39m loaders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mtargets\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m--> 136\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumerical\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    142\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(y_true, y_pred)\n\u001b[1;32m    143\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(cm, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBlues\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[42], line 61\u001b[0m, in \u001b[0;36mDebertaFakeReviewDetector.forward\u001b[0;34m(self, input_ids, attention_mask, numerical)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, attention_mask, numerical):\n\u001b[0;32m---> 61\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeberta\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     63\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\u001b[38;5;28mcls\u001b[39m, numerical], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:796\u001b[0m, in \u001b[0;36mDebertaV2Model.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    786\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    788\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    789\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    790\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    793\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m    794\u001b[0m )\n\u001b[0;32m--> 796\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    803\u001b[0m encoded_layers \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:669\u001b[0m, in \u001b[0;36mDebertaV2Encoder.forward\u001b[0;34m(self, hidden_states, attention_mask, output_hidden_states, output_attentions, query_states, relative_pos, return_dict)\u001b[0m\n\u001b[1;32m    659\u001b[0m     output_states, attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    660\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    661\u001b[0m         next_kv,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    666\u001b[0m         output_attentions,\n\u001b[1;32m    667\u001b[0m     )\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m     output_states, attn_weights \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnext_kv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[1;32m    679\u001b[0m     all_attentions \u001b[38;5;241m=\u001b[39m all_attentions \u001b[38;5;241m+\u001b[39m (attn_weights,)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:437\u001b[0m, in \u001b[0;36mDebertaV2Layer.forward\u001b[0;34m(self, hidden_states, attention_mask, query_states, relative_pos, rel_embeddings, output_attentions)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    430\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    435\u001b[0m     output_attentions: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    436\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, Optional[torch\u001b[38;5;241m.\u001b[39mTensor]]:\n\u001b[0;32m--> 437\u001b[0m     attention_output, att_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[1;32m    446\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:370\u001b[0m, in \u001b[0;36mDebertaV2Attention.forward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    363\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    368\u001b[0m     rel_embeddings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    369\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, Optional[torch\u001b[38;5;241m.\u001b[39mTensor]]:\n\u001b[0;32m--> 370\u001b[0m     self_output, att_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    379\u001b[0m         query_states \u001b[38;5;241m=\u001b[39m hidden_states\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:250\u001b[0m, in \u001b[0;36mDisentangledSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelative_attention:\n\u001b[1;32m    249\u001b[0m     rel_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_dropout(rel_embeddings)\n\u001b[0;32m--> 250\u001b[0m     rel_att \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisentangled_attention_bias\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_factor\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rel_att \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    255\u001b[0m     attention_scores \u001b[38;5;241m=\u001b[39m attention_scores \u001b[38;5;241m+\u001b[39m rel_att\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:343\u001b[0m, in \u001b[0;36mDisentangledSelfAttention.disentangled_attention_bias\u001b[0;34m(self, query_layer, key_layer, relative_pos, rel_embeddings, scale_factor)\u001b[0m\n\u001b[1;32m    341\u001b[0m     p2c_pos \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;241m-\u001b[39mr_pos \u001b[38;5;241m+\u001b[39m att_span, \u001b[38;5;241m0\u001b[39m, att_span \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    342\u001b[0m     p2c_att \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(key_layer, pos_query_layer\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m--> 343\u001b[0m     p2c_att \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mp2c_att\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp2c_pos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mquery_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    348\u001b[0m     score \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m p2c_att \u001b[38;5;241m/\u001b[39m scale\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mp2c_att\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 44.53 GiB of which 43.25 MiB is free. Process 569574 has 44.48 GiB memory in use. Of the allocated memory 43.63 GiB is allocated by PyTorch, and 353.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import pandas as pd\n",
    "\n",
    "    # Load your enriched DataFrame\n",
    "    df = enriched_df\n",
    "\n",
    "    run_training(\n",
    "        df,\n",
    "        batch_size=4,\n",
    "        epochs=5,\n",
    "        lr=0.001,\n",
    "        max_len=128\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
