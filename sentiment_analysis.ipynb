{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c92a4eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas numpy spacy transformers torch vaderSentiment textblob\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6de9bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tiktoken sentencepiece protobuf transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb7c40fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                                       # Data handling[1]\n",
    "import numpy as np                                        # Numerical operations[1]\n",
    "import spacy                                              # NLP and aspect extraction[2]\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer  # Overall sentiment[3]\n",
    "from textblob import TextBlob                            # Fallback sentiment[4]\n",
    "from transformers import pipeline                        # Pretrained ABSA model[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "780e25ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 5/5 [00:07<00:00,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final shape: (2025, 13)\n",
      "                      category  \\\n",
      "0  Cell_Phones_and_Accessories   \n",
      "1  Cell_Phones_and_Accessories   \n",
      "2  Cell_Phones_and_Accessories   \n",
      "3  Cell_Phones_and_Accessories   \n",
      "4  Cell_Phones_and_Accessories   \n",
      "\n",
      "                                               image  \n",
      "0  [https://images-na.ssl-images-amazon.com/image...  \n",
      "1  [https://images-na.ssl-images-amazon.com/image...  \n",
      "2  [https://images-na.ssl-images-amazon.com/image...  \n",
      "3  [https://images-na.ssl-images-amazon.com/image...  \n",
      "4  [https://images-na.ssl-images-amazon.com/image...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import gzip\n",
    "from tqdm import tqdm  # For progress tracking (optional)\n",
    "import os\n",
    "\n",
    "file_paths = [\n",
    "    \"Data/Reviews with images/Cell_Phones_and_Accessories_5.json.gz\",\n",
    "    \"Data/Reviews with images/Magazine_Subscriptions_5.json.gz\",\n",
    "    \"Data/Reviews with images/Appliances_5 (1).json.gz\",\n",
    "    \"Data/Reviews with images/All_Beauty_5 (1).json.gz\",\n",
    "    \"Data/Reviews with images/AMAZON_FASHION_5 (1).json.gz\",\n",
    "]\n",
    "\n",
    "FILE_INFO = {\n",
    "    \"amazon_hackon/Data/Reviews with images/Cell_Phones_and_Accessories_5.json.gz\": \"Cell_Phones_and_Accessories\",\n",
    "    \"amazon_hackon/Data/Reviews with images/Magazine_Subscriptions_5.json.gz\": \"Magazine_Subscriptions\",\n",
    "    \"amazon_hackon/Data/Reviews with images/Appliances_5 (1).json.gz\": \"Appliances\",\n",
    "    \"amazon_hackon/Data/Reviews with images/All_Beauty_5 (1).json.gz\": \"All_Beauty\",\n",
    "    \"amazon_hackon/Data/Reviews with images/AMAZON_FASHION_5 (1).json.gz\": \"AMAZON_FASHION\"\n",
    "}\n",
    "\n",
    "# Create a reverse lookup based on just the filename for matching\n",
    "filename_to_category = {\n",
    "    os.path.basename(path): category\n",
    "    for path, category in FILE_INFO.items()\n",
    "}\n",
    "\n",
    "def process_file(file_path, sample_size=1000):\n",
    "    valid_rows = []\n",
    "    try:\n",
    "        with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    record = json.loads(line)\n",
    "                    if isinstance(record.get('image'), list) and record['image']:\n",
    "                        if isinstance(record.get('reviewText'), str):  # Add this check\n",
    "                            valid_rows.append(record)\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    df = pd.DataFrame(valid_rows)\n",
    "    \n",
    "    # Sample if we have more than sample_size\n",
    "    if len(df) > sample_size:\n",
    "        df = df.sample(n=sample_size, random_state=42)\n",
    "\n",
    "    # Add category based on filename\n",
    "    category = filename_to_category.get(os.path.basename(file_path), \"Unknown\")\n",
    "    df[\"category\"] = category\n",
    "\n",
    "    return df\n",
    "\n",
    "df_chunks = []\n",
    "for path in tqdm(file_paths, desc=\"Processing files\"):\n",
    "    df_chunk = process_file(path)\n",
    "    if not df_chunk.empty:\n",
    "        df_chunks.append(df_chunk)\n",
    "\n",
    "if df_chunks:\n",
    "    df_with_images = pd.concat(df_chunks, ignore_index=True)\n",
    "    print(\"\\nFinal shape:\", df_with_images.shape)\n",
    "    print(df_with_images[['category', 'image']].head())\n",
    "else:\n",
    "    print(\"No valid data found in any files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e9cb3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not the greatest design but better than mine. Broke really easy in the first drop but nothing acrylic glue couldn't fix.  Acrylic glue doesn't fix hiking trials,\n"
     ]
    }
   ],
   "source": [
    "print(df_with_images['reviewText'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "465e873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print rows where 'reviewText' is not a string\n",
    "# non_string_mask = ~df_with_images['reviewText'].apply(lambda x: isinstance(x, str))\n",
    "# non_string_rows = df_with_images[non_string_mask]\n",
    "\n",
    "# print(\"Rows where 'reviewText' is NOT a string:\")\n",
    "# print(non_string_rows[['reviewerID', 'asin', 'reviewText', 'image']])\n",
    "# print(f\"\\nTotal non-string 'reviewText' entries: {len(non_string_rows)}\")\n",
    "# print(non_string_rows['reviewText'].apply(type))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b947a11d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>overall</th>\n",
       "      <th>vote</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>style</th>\n",
       "      <th>category</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>01 21, 2016</td>\n",
       "      <td>AD44H3YP65YHL</td>\n",
       "      <td>B00L9ICE9M</td>\n",
       "      <td>brian podolak</td>\n",
       "      <td>I bought this for my wife and she really loves...</td>\n",
       "      <td>Nice strong good looking case</td>\n",
       "      <td>1453334400</td>\n",
       "      <td>{'Size:': ' iPhone 6', 'Color:': ' White'}</td>\n",
       "      <td>Cell_Phones_and_Accessories</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>0.745222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>08 20, 2016</td>\n",
       "      <td>A2EAW9C31JE4L6</td>\n",
       "      <td>B00OS9E6AO</td>\n",
       "      <td>SmokingChicken</td>\n",
       "      <td>Not the greatest design but better than mine. ...</td>\n",
       "      <td>Hold it</td>\n",
       "      <td>1471651200</td>\n",
       "      <td>{'Color:': ' Black'}</td>\n",
       "      <td>Cell_Phones_and_Accessories</td>\n",
       "      <td>0.1545</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>11 30, 2015</td>\n",
       "      <td>A1DJ9ZJH1RKQIE</td>\n",
       "      <td>B017U7FQSG</td>\n",
       "      <td>Doleman</td>\n",
       "      <td>Really likes these cables, most of the micro U...</td>\n",
       "      <td>Packs of 5 colorful cables~</td>\n",
       "      <td>1448841600</td>\n",
       "      <td>{'Color:': ' 6.6ft-Red+Orange+Yellow+Green+Blue'}</td>\n",
       "      <td>Cell_Phones_and_Accessories</td>\n",
       "      <td>0.9743</td>\n",
       "      <td>0.396200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>10 5, 2015</td>\n",
       "      <td>A2XOUBTCDPFMBB</td>\n",
       "      <td>B0126SWVPA</td>\n",
       "      <td>inkling</td>\n",
       "      <td>Gooseneck mount:\\nOverall: sturdy quality for ...</td>\n",
       "      <td>Gooseneck cell phone holder: great quality ove...</td>\n",
       "      <td>1444003200</td>\n",
       "      <td>{'Color:': ' Gooseneck Phone holder'}</td>\n",
       "      <td>Cell_Phones_and_Accessories</td>\n",
       "      <td>0.9272</td>\n",
       "      <td>0.525836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>08 16, 2016</td>\n",
       "      <td>A2PNMOCPBH09K8</td>\n",
       "      <td>B013OZ6J5C</td>\n",
       "      <td>Timothy Lillis</td>\n",
       "      <td>I was worried because my bike was a little cro...</td>\n",
       "      <td>Better than I expected for prixe</td>\n",
       "      <td>1471305600</td>\n",
       "      <td>{'Color:': ' Basic Version'}</td>\n",
       "      <td>Cell_Phones_and_Accessories</td>\n",
       "      <td>0.9881</td>\n",
       "      <td>0.515598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  overall vote  verified  \\\n",
       "0  [https://images-na.ssl-images-amazon.com/image...      5.0  NaN     False   \n",
       "1  [https://images-na.ssl-images-amazon.com/image...      2.0  NaN      True   \n",
       "2  [https://images-na.ssl-images-amazon.com/image...      5.0  NaN     False   \n",
       "3  [https://images-na.ssl-images-amazon.com/image...      4.0    3     False   \n",
       "4  [https://images-na.ssl-images-amazon.com/image...      5.0  NaN     False   \n",
       "\n",
       "    reviewTime      reviewerID        asin    reviewerName  \\\n",
       "0  01 21, 2016   AD44H3YP65YHL  B00L9ICE9M   brian podolak   \n",
       "1  08 20, 2016  A2EAW9C31JE4L6  B00OS9E6AO  SmokingChicken   \n",
       "2  11 30, 2015  A1DJ9ZJH1RKQIE  B017U7FQSG         Doleman   \n",
       "3   10 5, 2015  A2XOUBTCDPFMBB  B0126SWVPA         inkling   \n",
       "4  08 16, 2016  A2PNMOCPBH09K8  B013OZ6J5C  Timothy Lillis   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  I bought this for my wife and she really loves...   \n",
       "1  Not the greatest design but better than mine. ...   \n",
       "2  Really likes these cables, most of the micro U...   \n",
       "3  Gooseneck mount:\\nOverall: sturdy quality for ...   \n",
       "4  I was worried because my bike was a little cro...   \n",
       "\n",
       "                                             summary  unixReviewTime  \\\n",
       "0                      Nice strong good looking case      1453334400   \n",
       "1                                            Hold it      1471651200   \n",
       "2                        Packs of 5 colorful cables~      1448841600   \n",
       "3  Gooseneck cell phone holder: great quality ove...      1444003200   \n",
       "4                   Better than I expected for prixe      1471305600   \n",
       "\n",
       "                                               style  \\\n",
       "0         {'Size:': ' iPhone 6', 'Color:': ' White'}   \n",
       "1                               {'Color:': ' Black'}   \n",
       "2  {'Color:': ' 6.6ft-Red+Orange+Yellow+Green+Blue'}   \n",
       "3              {'Color:': ' Gooseneck Phone holder'}   \n",
       "4                       {'Color:': ' Basic Version'}   \n",
       "\n",
       "                      category  polarity  subjectivity  \n",
       "0  Cell_Phones_and_Accessories    0.9920      0.745222  \n",
       "1  Cell_Phones_and_Accessories    0.1545      0.666667  \n",
       "2  Cell_Phones_and_Accessories    0.9743      0.396200  \n",
       "3  Cell_Phones_and_Accessories    0.9272      0.525836  \n",
       "4  Cell_Phones_and_Accessories    0.9881      0.515598  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader = SentimentIntensityAnalyzer()                      # VADER analyzer[3]\n",
    "\n",
    "def overall_sentiment(text):\n",
    "    scores = vader.polarity_scores(text)\n",
    "    polarity = scores[\"compound\"]                        # Range [-1,1]\n",
    "    subjectivity = TextBlob(text).sentiment.subjectivity # Range [0,1]\n",
    "    return pd.Series({\"polarity\": polarity, \"subjectivity\": subjectivity})\n",
    "\n",
    "# Apply to all reviews\n",
    "df_with_images = df_with_images[df_with_images['reviewText'].apply(lambda x: isinstance(x, str))]\n",
    "sent_scores = df_with_images[\"reviewText\"].apply(overall_sentiment)\n",
    "df2 = pd.concat([df_with_images, sent_scores], axis=1)                # Append features[1]\n",
    "df2.head()  # Display first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37a34af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2025, 15)\n"
     ]
    }
   ],
   "source": [
    "# Saving the dataset with sentiments\n",
    "print(df2.shape)\n",
    "df2.to_pickle(\"datasetFinal.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efeef046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load(\"en_core_web_sm\")               \n",
    "\n",
    "# def extract_aspects(text):\n",
    "#     doc = nlp(text)\n",
    "#     return [chunk.text.lower().strip() for chunk in doc.noun_chunks if len(chunk.text.split()) <= 3]\n",
    "\n",
    "# # Build global aspect list from top frequent chunks\n",
    "# all_chunks = df_with_images[\"reviewText\"].apply(extract_aspects).explode()\n",
    "# top_aspects = all_chunks.value_counts().head(50).index.tolist()  # Top 50 aspects[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01bc5f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# import pandas as pd\n",
    "# from collections import Counter\n",
    "\n",
    "# # Load spaCy model\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# # Define stopwords and uninformative terms to exclude\n",
    "# stopwords = nlp.Defaults.stop_words\n",
    "# custom_exclusions = {\n",
    "#     'i', 'it', 'you', 'that', 'this', 'they', 'me', 'we', 'them', 'which', \n",
    "#     'who', 'something', 'anything', 'everything', 'someone', 'anyone', 'some',\n",
    "#     'all', 'a', 'an', 'the', 'what', 'there', 'here', 'other', 'others'\n",
    "# }\n",
    "\n",
    "# def extract_aspects(text):\n",
    "#     \"\"\"Extract meaningful noun chunks from text\"\"\"\n",
    "#     doc = nlp(text)\n",
    "#     aspects = []\n",
    "    \n",
    "#     for chunk in doc.noun_chunks:\n",
    "#         # Filter by length and content quality\n",
    "#         tokens = [token.text.lower() for token in chunk]\n",
    "#         chunk_text = chunk.text.lower().strip()\n",
    "        \n",
    "#         # Skip if any of these conditions are true:\n",
    "#         if (\n",
    "#             len(chunk) > 3 or  # Too long\n",
    "#             chunk_text in custom_exclusions or  # In exclusion list\n",
    "#             all(token in stopwords for token in tokens) or  # All stopwords\n",
    "#             any(token in custom_exclusions for token in tokens)  # Contains excluded terms\n",
    "#         ):\n",
    "#             continue\n",
    "            \n",
    "#         aspects.append(chunk_text)\n",
    "        \n",
    "#     return aspects\n",
    "\n",
    "# # Build global aspect list\n",
    "# all_chunks = df_with_images[\"reviewText\"].apply(extract_aspects).explode()\n",
    "\n",
    "# # Filter and get top aspects\n",
    "# aspect_counts = all_chunks.value_counts()\n",
    "# meaningful_aspects = [\n",
    "#     aspect for aspect in aspect_counts.index\n",
    "#     if not any(excl_word in aspect for excl_word in custom_exclusions)\n",
    "# ]\n",
    "# top_aspects = aspect_counts.loc[meaningful_aspects].head(50).index.tolist()\n",
    "\n",
    "# print(\"Top 50 meaningful aspects:\")\n",
    "# print(top_aspects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "549e8bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nTop 50 aspects:\")\n",
    "# for aspect in top_aspects:\n",
    "#     print(aspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f8df3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "# import torch\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from tqdm import tqdm\n",
    "# from collections import defaultdict\n",
    "\n",
    "# # Initialize device\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Using device: {device}\")\n",
    "\n",
    "# # Load ABSA model and tokenizer (with error handling)\n",
    "# try:\n",
    "#     model_name = \"yangheng/deberta-v3-base-absa-v1.1\"\n",
    "#     tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)  # Disable fast tokenizer\n",
    "#     model = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)\n",
    "#     print(\"Model loaded successfully\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error loading model: {e}\")\n",
    "#     # Fallback to smaller model\n",
    "#     model_name = \"yangheng/deberta-v3-small-absa-v1.1\"\n",
    "#     tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "#     model = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)\n",
    "#     print(\"Using smaller model as fallback\")\n",
    "\n",
    "# # Batch processing function for efficiency\n",
    "# def batch_process_aspect_sentiment(text_aspect_pairs, batch_size=8):\n",
    "#     \"\"\"\n",
    "#     Process aspect sentiment in batches for efficiency\n",
    "#     Returns: dict of {(text, aspect): (label, score)}\n",
    "#     \"\"\"\n",
    "#     results = {}\n",
    "#     num_batches = int(np.ceil(len(text_aspect_pairs) / batch_size))\n",
    "    \n",
    "#     for i in tqdm(range(num_batches), desc=\"Processing ABSA batches\"):\n",
    "#         batch = text_aspect_pairs[i*batch_size : (i+1)*batch_size]\n",
    "#         formatted_inputs = [f\"[CLS] {text} [SEP] {aspect} [SEP]\" for text, aspect in batch]\n",
    "        \n",
    "#         try:\n",
    "#             inputs = tokenizer(\n",
    "#                 formatted_inputs,\n",
    "#                 padding=True,\n",
    "#                 truncation=True,\n",
    "#                 max_length=512,\n",
    "#                 return_tensors=\"pt\"\n",
    "#             ).to(device)\n",
    "            \n",
    "#             with torch.no_grad():\n",
    "#                 outputs = model(**inputs)\n",
    "            \n",
    "#             probs = torch.softmax(outputs.logits, dim=1)\n",
    "#             preds = torch.argmax(probs, dim=1)\n",
    "            \n",
    "#             for j, (text, aspect) in enumerate(batch):\n",
    "#                 label_id = preds[j].item()\n",
    "#                 label = model.config.id2label[label_id]\n",
    "#                 score = probs[j, label_id].item()\n",
    "#                 results[(text, aspect)] = (label, score)\n",
    "                \n",
    "#         except RuntimeError as e:\n",
    "#             print(f\"Batch {i} failed: {e}\")\n",
    "#             # Fallback to individual processing\n",
    "#             for text, aspect in batch:\n",
    "#                 try:\n",
    "#                     inputs = tokenizer(\n",
    "#                         f\"[CLS] {text} [SEP] {aspect} [SEP]\",\n",
    "#                         return_tensors=\"pt\",\n",
    "#                         truncation=True,\n",
    "#                         max_length=512\n",
    "#                     ).to(device)\n",
    "                    \n",
    "#                     with torch.no_grad():\n",
    "#                         outputs = model(**inputs)\n",
    "                    \n",
    "#                     probs = torch.softmax(outputs.logits, dim=1)\n",
    "#                     label_id = torch.argmax(probs).item()\n",
    "#                     label = model.config.id2label[label_id]\n",
    "#                     score = probs[0, label_id].item()\n",
    "#                     results[(text, aspect)] = (label, score)\n",
    "                    \n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Failed on ({text[:20]}..., {aspect}): {e}\")\n",
    "#                     results[(text, aspect)] = ('Neutral', 0.0)\n",
    "    \n",
    "#     return results\n",
    "\n",
    "# # Optimized ABSA feature extraction\n",
    "# def generate_absa_features(df, top_aspects, batch_size=32):\n",
    "#     \"\"\"\n",
    "#     Generate ABSA features with aspect filtering and batch processing\n",
    "#     \"\"\"\n",
    "#     # Step 1: Collect all (text, aspect) pairs to process\n",
    "#     text_aspect_pairs = []\n",
    "#     review_aspect_map = defaultdict(list)\n",
    "    \n",
    "#     # First pass: Extract aspects and create processing list\n",
    "#     for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Preparing aspects\"):\n",
    "#         text = row['reviewText']\n",
    "#         detected = set(extract_aspects(text)) & set(top_aspects)\n",
    "        \n",
    "#         for aspect in detected:\n",
    "#             text_aspect_pairs.append((text, aspect))\n",
    "#             review_aspect_map[idx].append(aspect)\n",
    "    \n",
    "#     # Step 2: Batch process all aspect-sentiment pairs\n",
    "#     sentiment_results = batch_process_aspect_sentiment(text_aspect_pairs, batch_size)\n",
    "    \n",
    "#     # Step 3: Build features DataFrame\n",
    "#     features = []\n",
    "#     for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Building features\"):\n",
    "#         feats = {}\n",
    "#         detected_aspects = review_aspect_map.get(idx, [])\n",
    "        \n",
    "#         # Add features for detected aspects\n",
    "#         for aspect in detected_aspects:\n",
    "#             label, score = sentiment_results.get((row['reviewText'], aspect), ('Neutral', 0.0))\n",
    "            \n",
    "#             if label == 'Positive':\n",
    "#                 polarity = score\n",
    "#             elif label == 'Negative':\n",
    "#                 polarity = -score\n",
    "#             else:\n",
    "#                 polarity = 0.0\n",
    "                \n",
    "#             feats[f\"{aspect}_polarity\"] = polarity\n",
    "#             feats[f\"{aspect}_presence\"] = 1\n",
    "        \n",
    "#         # Add zero features for non-detected aspects\n",
    "#         for aspect in set(top_aspects) - set(detected_aspects):\n",
    "#             feats[f\"{aspect}_polarity\"] = 0.0\n",
    "#             feats[f\"{aspect}_presence\"] = 0\n",
    "            \n",
    "#         features.append(feats)\n",
    "    \n",
    "#     return pd.DataFrame(features)\n",
    "\n",
    "# # Generate ABSA features\n",
    "# absa_df = generate_absa_features(df_with_images, top_aspects)\n",
    "\n",
    "# # Combine with original data\n",
    "# df3 = pd.concat([df_with_images, absa_df], axis=1)\n",
    "# print(\"ABSA features added successfully!\")\n",
    "# print(f\"Final shape: {df3.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c1ca387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df3.iloc[0,])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a51f3f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Assume df3 is your DataFrame with ABSA features appended\n",
    "# # Identify all polarity columns (ending with '_polarity')\n",
    "# polarity_cols = [col for col in df3.columns if (col.endswith('_polarity') or col.endswith('_presence'))]\n",
    "\n",
    "# # Compute non-zero counts for each polarity column\n",
    "# non_zero_counts = (df3[polarity_cols] != 0.0).sum().sort_values(ascending=False)\n",
    "\n",
    "# # Display the counts\n",
    "# print(\"Non-zero counts per aspect polarity column:\\n\", non_zero_counts)\n",
    "# print(\"\\nTotal non-zero polarity columns:\", len(non_zero_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fb221d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
